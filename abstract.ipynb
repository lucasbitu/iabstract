{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ralfferreira/generate-abstract/blob/main/abstract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalando as bibliotecas\n",
        "\n",
        "!pip install -q datasets\n",
        "!pip install -q transformers\n",
        "!pip install -q evaluate"
      ],
      "metadata": {
        "id": "Rpl9nEfALUtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgSkrDl-I2Ov"
      },
      "outputs": [],
      "source": [
        "# Importando a base de dados, definindo a de teste\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"scientific_papers\", \"arxiv\", split = 'test', streaming=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando o modelo\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\") # Iremos testar outros modelos"
      ],
      "metadata": {
        "id": "Jjtq8vMAMHjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando dois tipos de base de dados\n",
        "\n",
        "## Treino\n",
        "small_train_dataset = dataset.shuffle(seed=42, buffer_size=200)\n",
        "\n",
        "## Avaliação\n",
        "small_eval_dataset = dataset.shuffle(seed=42, buffer_size=200)"
      ],
      "metadata": {
        "id": "aOGiJF8qPg_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar os dados\n",
        "\n",
        "dataset_head = small_train_dataset.take(2)\n",
        "list(dataset_head)"
      ],
      "metadata": {
        "id": "xT7kz0mEPxdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A partir daqui é desenvolvimento (contém bugs)"
      ],
      "metadata": {
        "id": "CyD_bWnsfTmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parte inicial do treinamento do modelo\n",
        "\n",
        "# from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir=\"test_trainer\", \n",
        "#     evaluation_strategy=\"epoch\", \n",
        "#     per_device_train_batch_size = 2)"
      ],
      "metadata": {
        "id": "KWLXaRvsSZiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Métricas de 'summarization'\n",
        "# O rogue é baseado no cálculo das pontuações de precisão e recuperação para a sobreposição\n",
        "\n",
        "# import numpy as np\n",
        "# import evaluate\n",
        "\n",
        "# !pip install -q rouge_score\n",
        "\n",
        "# rouge_score = evaluate.load(\"rouge\")"
      ],
      "metadata": {
        "id": "DXBo_TbdRmHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q sentence_transformers"
      ],
      "metadata": {
        "id": "hxzRlLlyXUfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos pegar o abstract que a gente gerou do artigo, a partir disso vamos \n",
        "# comparar com o abstract original do artigo original que geramos o abstract\n",
        "\n",
        "# from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Single list of sentences\n",
        "# sentences = ['The cat sits outside',\n",
        "#              'A man is playing guitar',\n",
        "#              'I love pasta',\n",
        "#              'The new movie is awesome',\n",
        "#              'The cat plays in the garden',\n",
        "#              'A woman watches TV',\n",
        "#              'The new movie is so great',\n",
        "#              'Do you like pizza?']\n",
        "\n",
        "# Compute embeddings\n",
        "# embeddings = model.encode(sentences, convert_to_tensor=True)\n",
        "\n",
        "# Compute cosine-similarities for each sentence with each other sentence\n",
        "# cosine_scores = util.cos_sim(embeddings, embeddings)\n",
        "\n",
        "# Find the pairs with the highest cosine similarity scores\n",
        "# pairs = []\n",
        "# for i in range(len(cosine_scores)-1):\n",
        "#     for j in range(i+1, len(cosine_scores)):\n",
        "#         pairs.append({'index': [i, j], 'score': cosine_scores[i][j]})\n",
        "\n",
        "# Sort scores in decreasing order\n",
        "# pairs = sorted(pairs, key=lambda x: x['score'], reverse=True)\n",
        "\n",
        "# for pair in pairs[0:10]:\n",
        "#     i, j = pair['index']\n",
        "#     print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences[i], sentences[j], pair['score']))  "
      ],
      "metadata": {
        "id": "Gg0cNPw8XC2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para o modelo, precisamos decodificar as saídas e os rótulos em texto antes de \n",
        "# podermos calcular as pontuações/métricas do Rouge\n",
        "\n",
        "# def compute_metrics(eval_pred):\n",
        "#     predictions, labels = eval_pred\n",
        "\n",
        "#     # Decode generated summaries into text\n",
        "#     decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "\n",
        "#     # Replace -100 in the labels as we can't decode them\n",
        "#     labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "#     # Decode reference summaries into text\n",
        "#     decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "#     # ROUGE expects a newline after each sentence\n",
        "#     decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "#     decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "\n",
        "#     # Compute ROUGE scores\n",
        "#     result = rouge_score.compute(\n",
        "#         predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
        "#     )\n",
        "#     \n",
        "# Extract the median scores\n",
        "#     result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "#     return {k: round(v, 4) for k, v in result.items()}"
      ],
      "metadata": {
        "id": "7t5aPy-rUHAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer = Trainer(\n",
        "#     model=summarizer,\n",
        "#     args=training_args,\n",
        "#     train_dataset=small_train_dataset,\n",
        "#     eval_dataset=small_eval_dataset,\n",
        "#     compute_metrics=compute_metrics,\n",
        "# )"
      ],
      "metadata": {
        "id": "SSfJf1QhRyo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# torch.cuda.empty_cache()\n",
        "# trainer.train()"
      ],
      "metadata": {
        "id": "dBFIR5nKS9ty"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}